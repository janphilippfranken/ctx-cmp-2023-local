hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  # sweep:
  #   dir: .
  #   subdir: .
  # job_logging:
  #   root:
  #     level: INFO
  job:
    env_set:
      TOKENIZERS_PARALLELISM: "false"
      CUDA_VISIBLE_DEVICES: "0,1"  # make sure to keep this number small to avoid crash on ccn!

defaults:
  - base_config
  - _self_

model:
  model_name_or_path: bigscience/bloomz-560m
  cache_dir: .cache/ # have to change to data on ccn to avoid crash! 

# training:
#   generation_max_length: 128

data:
  dataset_name: stas/openwebtext-10k
  cache_dir: .cache/